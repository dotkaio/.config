
l
t
z
.
T
~
ls
td
..
./
ip
lms
pip
list
zshrc
speed
santa
micro
clear
conda
t -L2
ollama
update
python
code .
adduser
./micro
.config
Desktop
npm run
man list
git push
compinit
Contents
pnpm dev
rand user
rand pass
Developer
hey there
md Speach
cd Speach
python -V
Resources
cd Desktop
conda init
conda list
python3 -V
ollama show
ollama list
npm run dev
READNULLCMD
santa status
open -a Text
rm .DS_Store
cd Developer
which python
pnpm install
ollama create
rm .zcompdump
cat README.md
ollama show -h
conda activate
cd Magellan.app
open -a TextEdit
env | grep shell
env | grep SHELL
Developer/Speach
cd /Applications
pnpm self-update
open .bash_profile
rm .config/histfile
env | grep -E shell
env | grep -i shell
mv speach.py Speach
source .bash_profile
conda activate speach
curl https://getmic.ro
sudo killall $(whoami)
ollama run llama3.2:1b
conda create -n speach
ollama show --modelfile
remove eloston-chromium
react-invoice-generator
ollama show ---modelfile
install eloston-chromium
sudo killall -u $(whoami)
pip install --upgrade pip
What it means "askmo bros"
git config --global --edit
mv Ask\ april.txt ~/Desktop
open react-invoice-generator
curl https://getmic.ro | bash
open ~/Desktop/INV019379-2.pdf
mv speach.py Developer/speach.py
Developer/react-invoice-generator
git commit --amend --reset-author
len xszetgdhouwsfrdsoasobmruyjwnwp
ollama run llama3.2:1b --verbose \\
open 67577b8bbf30926518ac2384_ballon.png
len xszetgdhouwsfrdsoasobmruyjwnwpbwr0qlo0ed
/Users/sysadm/Developer/voice-assistant-frontend
git add . && git commit -m "new function for conda"
/Applications/Magellan.app/Contents/MacOS/Magellan -h
echo "ANTIBIOTIC FREE. HUMANELY RAISED MEATS" | lower | pc
git add . && git commit -m 'littlesnitch firewall rules' && git push
yt-dlp "https://www.tiktok.com/@kenshirorealstar/video/7366504884092276000"
mv TriNet\ Warriors\ at\ Work\ ｃ�\ Reece\ Beekman\ \[1631828534383904\].mp4 Todd.mp4
say "How's it going? Is there something I can help you with or would you like to chat?"
ollama show --modelfile .ollama/models/manifests/registry.ollama.ai/library/llama3.2-vision
ollama show --modelfile .ollama/models/manifests/registry.ollama.ai/library/llama3.2-vision/latest
curl -O https://cdn.prod.website-files.com/67533275c99c2839ab392c87/67577b8bbf30926518ac2384_ballon.png
curl -O https://storeforcesolutions.com/wp-content/themes/storeforce/assets/img/i-storeceforce-icon.svg
curl -O https://cdn.prod.website-files.com/67533275c99c2839ab392c87/6757a20a227985a9a7cee5c2_logoaskapril.png
yt-dlp "https://www.facebook.com/watch/?extid=SMS-UNK-UNK-UNK-IOS_GK0T-GK1C&mibextid=gkx3sN&v=1631828534383904"
curl -O https://cdn.prod.website-files.com/5d7517ff7288d5a70b3b64bd/613b6a6361dc95d04258d19b_script.txt magic_effect.jsconda activate a0
conda activate a0
 /usr/bin/env /opt/homebrew/Caskroom/miniconda/base/envs/a0/bin/python /Users/sysadm/.vscode/extensions/ms-python.debugpy-2024.14.0-darwin-arm64/bundled/libs/debugpy/adapter/../../debugpy/launcher 55066 -- ./run_ui.py -Xfrozen_modules=off 
conda init
conda activate a0
pip 
pip install -r requirements.txt 
code README.md
z
conda activate
conda init
rm ~/.zcompdump&&compitinit
compinit
conda remove a0
conda deactivate a0
finder a0
finder -E 'a0'
finder -i a0
t
python run_cli.py
clear
conda activate a0
conda init
exit
clear
conda
conda activate a0
conda init
clear
bash
exit
brew remove conda
brew remove miniconda
t
brew install miniconda
bash
exit
t\\
t
cd Developer
t
a0
t
conda init
conda create -n a0 
conda activate a0
zshrc
t
update
t
ollama run llama3.2:1b
conda init
z
z
conda init
conda create -n a0 python=3.12 -y
conda activate a0
pip install -r requirements.txt 
clear
ollama list
ollama pull llama3.2:3b-instruct-fp16
python run_ui.py
